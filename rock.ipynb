{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a053c4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading and Preprocessing Data ---\n",
      "Original Dataset Shape: (121575, 24)\n",
      "Columns with all missing values: []\n",
      "--- Step 2: Handling Missing Values ---\n",
      "Imputing missing values in column 'Date' with mode value: '2013-03-02'\n",
      "Imputing missing values in column 'Location' with mode value: 'Canberra'\n",
      "Imputing missing values in column 'WindGustDir' with mode value: 'W'\n",
      "Imputing missing values in column 'WindDir9am' with mode value: 'N'\n",
      "Imputing missing values in column 'WindDir3pm' with mode value: 'W'\n",
      "Label encoding categorical columns...\n",
      "Running MICE imputation on numerical features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after imputation: (121575, 22)\n",
      "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
      "0     20.4     25.8       0.0          6.0      12.4          6.0   \n",
      "1     20.9     26.7       0.2          8.0      10.3          3.0   \n",
      "2     22.3     26.3       0.0          3.2       2.0          0.0   \n",
      "3     21.6     22.2       1.2          2.8       0.0          2.0   \n",
      "4     20.4     23.5       2.6          2.2       2.9          2.0   \n",
      "5     20.4     24.4       0.0          3.0       8.7          0.0   \n",
      "\n",
      "   WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  ...  Humidity3pm  \\\n",
      "0           31.0         6.0         7.0          13.0  ...         71.0   \n",
      "1           31.0         5.0         4.0          15.0  ...         77.0   \n",
      "2           35.0         1.0         9.0           6.0  ...         90.0   \n",
      "3           41.0         2.0         2.0          20.0  ...         95.0   \n",
      "4           52.0         2.0         2.0          24.0  ...         86.0   \n",
      "5           48.0         2.0         2.0          30.0  ...         79.0   \n",
      "\n",
      "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
      "0       1014.5       1013.6       3.0       1.0     23.3     24.7        0.0   \n",
      "1       1016.3       1015.5       2.0       5.0     25.0     25.1        0.0   \n",
      "2       1014.6       1014.3       7.0       7.0     24.7     23.8        0.0   \n",
      "3       1016.0       1015.3       8.0       8.0     22.1     21.2        1.0   \n",
      "4       1015.3       1013.7       7.0       7.0     21.8     21.6        1.0   \n",
      "5       1014.5       1012.7       5.0       3.0     21.4     23.3        0.0   \n",
      "\n",
      "   RISK_MM  RainTomorrow  \n",
      "0      0.2           0.0  \n",
      "1      0.0           0.0  \n",
      "2      1.2           1.0  \n",
      "3      2.6           1.0  \n",
      "4      0.0           0.0  \n",
      "5      0.0           0.0  \n",
      "\n",
      "[6 rows x 22 columns]\n",
      "\n",
      "--- Pearson Correlation with 'RainTomorrow' ---\n",
      "RainTomorrow     1.000000\n",
      "RISK_MM          0.502849\n",
      "Humidity3pm      0.445370\n",
      "Cloud3pm         0.423422\n",
      "Cloud9am         0.346015\n",
      "RainToday        0.315461\n",
      "Humidity9am      0.254272\n",
      "Rainfall         0.243048\n",
      "WindGustSpeed    0.235910\n",
      "WindSpeed9am     0.091937\n",
      "WindSpeed3pm     0.090398\n",
      "MinTemp          0.073317\n",
      "WindGustDir      0.062669\n",
      "WindDir3pm       0.042008\n",
      "WindDir9am       0.036469\n",
      "Temp9am         -0.033754\n",
      "Evaporation     -0.139328\n",
      "MaxTemp         -0.163782\n",
      "Temp3pm         -0.197142\n",
      "Pressure3pm     -0.239583\n",
      "Pressure9am     -0.260806\n",
      "Sunshine        -0.479927\n",
      "Name: RainTomorrow, dtype: float64\n",
      "'RISK_MM' feature removed to prevent data leakage.\n",
      "\n",
      "Updated dataset shape: (121575, 21)\n",
      "\n",
      "First 5 rows after removing 'RISK_MM':\n",
      "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
      "0     20.4     25.8       0.0          6.0      12.4          6.0   \n",
      "1     20.9     26.7       0.2          8.0      10.3          3.0   \n",
      "2     22.3     26.3       0.0          3.2       2.0          0.0   \n",
      "3     21.6     22.2       1.2          2.8       0.0          2.0   \n",
      "4     20.4     23.5       2.6          2.2       2.9          2.0   \n",
      "\n",
      "   WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  ...  Humidity9am  \\\n",
      "0           31.0         6.0         7.0          13.0  ...         84.0   \n",
      "1           31.0         5.0         4.0          15.0  ...         79.0   \n",
      "2           35.0         1.0         9.0           6.0  ...         87.0   \n",
      "3           41.0         2.0         2.0          20.0  ...         92.0   \n",
      "4           52.0         2.0         2.0          24.0  ...         86.0   \n",
      "\n",
      "   Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
      "0         71.0       1014.5       1013.6       3.0       1.0     23.3   \n",
      "1         77.0       1016.3       1015.5       2.0       5.0     25.0   \n",
      "2         90.0       1014.6       1014.3       7.0       7.0     24.7   \n",
      "3         95.0       1016.0       1015.3       8.0       8.0     22.1   \n",
      "4         86.0       1015.3       1013.7       7.0       7.0     21.8   \n",
      "\n",
      "   Temp3pm  RainToday  RainTomorrow  \n",
      "0     24.7        0.0           0.0  \n",
      "1     25.1        0.0           0.0  \n",
      "2     23.8        0.0           1.0  \n",
      "3     21.2        1.0           1.0  \n",
      "4     21.6        1.0           0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Original Class Distribution:\n",
      " RainTomorrow\n",
      "0.0    0.773901\n",
      "1.0    0.226099\n",
      "Name: proportion, dtype: float64\n",
      "Training Set Class Distribution:\n",
      " RainTomorrow\n",
      "0.0    0.773907\n",
      "1.0    0.226093\n",
      "Name: proportion, dtype: float64\n",
      "Testing Set Class Distribution:\n",
      " RainTomorrow\n",
      "0.0    0.773888\n",
      "1.0    0.226112\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Step 3: Oversampling and Handling Outliers on Training Data ---\n",
      "Class distribution after oversampling:\n",
      " RainTomorrow\n",
      "0.0    65861\n",
      "1.0    65861\n",
      "Name: count, dtype: int64\n",
      "Final shape after outlier removal: (102217, 21)\n",
      "Final class distribution:\n",
      " RainTomorrow\n",
      "0.0    0.562871\n",
      "1.0    0.437129\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Final Cleaned Training Dataset (Preview) ---\n",
      "     MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
      "2   0.098540  1.075745 -0.279788     0.652710  0.220795    -1.700321   \n",
      "3  -0.304411  1.020290 -0.279788    -0.291671  0.645514    -0.207745   \n",
      "4  -2.396658 -1.045399 -0.279788    -0.183201  0.787087    -1.273871   \n",
      "7  -0.164928  0.507334 -0.279788    -0.508611 -0.062350    -0.207745   \n",
      "10 -1.342786 -0.851308 -0.279788    -0.605210  0.588885    -0.634196   \n",
      "\n",
      "    WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  ...  Humidity9am  \\\n",
      "2        0.197666   -1.550710    0.025917      0.869967  ...    -1.145685   \n",
      "3       -0.246736   -0.887302   -0.405110     -1.624017  ...     1.625599   \n",
      "4        0.716135    0.439515    0.241430     -0.150299  ...    -0.779666   \n",
      "7        1.160536   -0.223893   -0.189596     -0.150299  ...    -1.302550   \n",
      "10      -1.505874   -1.329574   -0.620623     -0.377025  ...    -0.465936   \n",
      "\n",
      "    Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm   Temp9am  \\\n",
      "2     -1.000815    -0.208596    -0.494859  0.228637  1.467953  0.767784   \n",
      "3     -1.194349     0.746757     0.585199 -0.182971 -0.735212 -0.650681   \n",
      "4     -1.726568     1.919236     1.665256 -1.343098 -1.887184 -1.540994   \n",
      "7     -1.339500    -0.324397    -0.421882  0.228637  0.629169  0.511253   \n",
      "10    -0.613746     1.919236     1.825805 -1.736032 -0.926083 -0.907212   \n",
      "\n",
      "     Temp3pm  RainToday  RainTomorrow  \n",
      "2   1.225066   -0.54132           0.0  \n",
      "3   1.182702   -0.54132           0.0  \n",
      "4  -0.991947   -0.54132           0.0  \n",
      "7   0.660222   -0.54132           0.0  \n",
      "10 -0.794252   -0.54132           0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "✅ Final cleaned dataset saved as 'Cleaned-dataset.csv'\n",
      "\n",
      "--- Training Logistic Regression ---\n",
      "--- Logistic Regression Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.8795\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86     28226\n",
      "         1.0       0.54      0.81      0.65      8247\n",
      "\n",
      "    accuracy                           0.80     36473\n",
      "   macro avg       0.74      0.80      0.75     36473\n",
      "weighted avg       0.84      0.80      0.81     36473\n",
      "\n",
      "\n",
      "--- Training Random Forest ---\n",
      "--- Random Forest Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.9156\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.95      0.92     28226\n",
      "         1.0       0.77      0.62      0.69      8247\n",
      "\n",
      "    accuracy                           0.87     36473\n",
      "   macro avg       0.83      0.78      0.80     36473\n",
      "weighted avg       0.87      0.87      0.87     36473\n",
      "\n",
      "\n",
      "--- Training MLP Classifier ---\n",
      "--- MLP Classifier Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.9046\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91     28226\n",
      "         1.0       0.69      0.72      0.70      8247\n",
      "\n",
      "    accuracy                           0.86     36473\n",
      "   macro avg       0.80      0.81      0.81     36473\n",
      "weighted avg       0.87      0.86      0.86     36473\n",
      "\n",
      "\n",
      "--- Training XGBoost ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:04:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBoost Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.9143\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90     28226\n",
      "         1.0       0.65      0.78      0.71      8247\n",
      "\n",
      "    accuracy                           0.85     36473\n",
      "   macro avg       0.79      0.83      0.80     36473\n",
      "weighted avg       0.87      0.85      0.86     36473\n",
      "\n",
      "\n",
      "--- Training Neural Network ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1140/1140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step\n",
      "--- Neural Network Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.9243\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.90      0.92     28226\n",
      "         1.0       0.69      0.78      0.73      8247\n",
      "\n",
      "    accuracy                           0.87     36473\n",
      "   macro avg       0.81      0.84      0.82     36473\n",
      "weighted avg       0.88      0.87      0.87     36473\n",
      "\n",
      "\n",
      "--- Step 5: Final Model Comparison Summary ---\n",
      "                 Model   ROC_AUC  Precision_1  Recall_1  F1-Score_1\n",
      "4       Neural Network  0.924309          0.0       0.0         0.0\n",
      "1        Random Forest  0.915586          0.0       0.0         0.0\n",
      "3              XGBoost  0.914254          0.0       0.0         0.0\n",
      "2       MLP Classifier  0.904645          0.0       0.0         0.0\n",
      "0  Logistic Regression  0.879546          0.0       0.0         0.0\n",
      "\u001b[1m1140/1140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step\n",
      "\n",
      "--- Final Conclusion ---\n",
      "Based on ROC AUC and F1-Score for the minority class, the best performing model is likely: Neural Network\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping # type: ignore\n",
    "\n",
    "print(\"--- Step 1: Loading and Preprocessing Data ---\")\n",
    "try:\n",
    "    dataset = pd.read_csv('Extracted-dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Extracted-dataset.csv' not found. Please check the file path.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Original Dataset Shape:\", dataset.shape)\n",
    "\n",
    "# --- STEP 1: Encode binary target/label columns ---\n",
    "dataset['RainToday'] = dataset['RainToday'].map({'No': 0, 'Yes': 1})\n",
    "dataset['RainTomorrow'] = dataset['RainTomorrow'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Check for fully missing columns\n",
    "fully_missing_cols = dataset.columns[dataset.isnull().all()]\n",
    "print(\"Columns with all missing values:\", fully_missing_cols.tolist())\n",
    "\n",
    "# --- STEP 2: Handle Missing Values ---\n",
    "print(\"--- Step 2: Handling Missing Values ---\")\n",
    "\n",
    "# Isolate columns for different imputation strategies\n",
    "categorical_cols = dataset.select_dtypes(include=['object']).columns\n",
    "numerical_cols = dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "columns_to_impute = [col for col in dataset.columns if col not in ['Date', 'Location']]\n",
    "\n",
    "# Step 2.1: Impute object/categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    mode_value = dataset[col].mode()[0]\n",
    "    print(f\"Imputing missing values in column '{col}' with mode value: '{mode_value}'\")\n",
    "    dataset[col] = dataset[col].fillna(mode_value)\n",
    "\n",
    "# Step 2.2: Label Encode categorical columns\n",
    "print(\"Label encoding categorical columns...\")\n",
    "lencoders = {}\n",
    "for col in categorical_cols:\n",
    "    lencoders[col] = LabelEncoder()\n",
    "    dataset[col] = lencoders[col].fit_transform(dataset[col])\n",
    "\n",
    "# Prepare data for MICE imputation\n",
    "dataset_for_mice = dataset[columns_to_impute].copy()\n",
    "\n",
    "# Step 2.3: Impute numerical columns using Iterative Imputer (MICE)\n",
    "print(\"Running MICE imputation on numerical features...\")\n",
    "mice_imputer = IterativeImputer(random_state=42)\n",
    "dataset_imputed_array = mice_imputer.fit_transform(dataset_for_mice)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame with correct column names\n",
    "dataset_imputed = pd.DataFrame(dataset_imputed_array, columns=dataset_for_mice.columns)\n",
    "\n",
    "# Final check\n",
    "print(\"Shape after imputation:\", dataset_imputed.shape)\n",
    "print(dataset_imputed.head(6))\n",
    "\n",
    "# Step 1: Keep only numeric columns (needed for Pearson correlation)\n",
    "numeric_df = dataset_imputed.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Step 2: Get correlation of each numeric column with 'RainTomorrow'\n",
    "correlation_with_target = numeric_df.corr()['RainTomorrow'].sort_values(ascending=False)\n",
    "\n",
    "# Step 3: Print correlation values\n",
    "print(\"\\n--- Pearson Correlation with 'RainTomorrow' ---\")\n",
    "print(correlation_with_target)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x=correlation_with_target.drop('RainTomorrow').values,\n",
    "    y=correlation_with_target.drop('RainTomorrow').index\n",
    ")\n",
    "plt.title(\"Pearson Correlation with 'RainTomorrow'\")\n",
    "plt.xlabel(\"Correlation Coefficient\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_barplot.png')\n",
    "plt.close()\n",
    "\n",
    "# Make a copy to avoid changing the original data unintentionally\n",
    "data = dataset_imputed.copy()\n",
    "\n",
    "# Remove 'RISK_MM' if it exists\n",
    "if 'RISK_MM' in data.columns:\n",
    "    data.drop('RISK_MM', axis=1, inplace=True)\n",
    "    print(\"'RISK_MM' feature removed to prevent data leakage.\")\n",
    "else:\n",
    "    print(\"'RISK_MM' already removed or not present.\")\n",
    "\n",
    "# Display the shape and the first few rows to confirm\n",
    "print(\"\\nUpdated dataset shape:\", data.shape)\n",
    "print(\"\\nFirst 5 rows after removing 'RISK_MM':\")\n",
    "print(data.head())\n",
    "\n",
    "# X = all features except 'RainTomorrow', y = target variable\n",
    "X = data.drop('RainTomorrow', axis=1)\n",
    "y = data['RainTomorrow']\n",
    "\n",
    "# Split data before scaling to prevent data leakage from the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Apply StandardScaler only on the training data, then transform both train and test\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Check class balance\n",
    "print(\"Original Class Distribution:\\n\", y.value_counts(normalize=True))\n",
    "print(\"Training Set Class Distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Testing Set Class Distribution:\\n\", y_test.value_counts(normalize=True))\n",
    "\n",
    "# Plot class distribution in original training data\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y_train_df['RainTomorrow'], hue=y_train_df['RainTomorrow'], palette='pastel', legend=False)\n",
    "plt.title(\"Class Distribution Before Oversampling\")\n",
    "plt.xlabel(\"RainTomorrow (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig('class_distribution_before_oversampling.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n--- Step 3: Oversampling and Handling Outliers on Training Data ---\")\n",
    "df_train_combined = pd.concat([X_train_scaled, y_train.reset_index(drop=True)], axis=1)\n",
    "minority_class = df_train_combined[df_train_combined['RainTomorrow'] == 1]\n",
    "majority_class = df_train_combined[df_train_combined['RainTomorrow'] == 0]\n",
    "\n",
    "if not minority_class.empty:\n",
    "    minority_oversampled = resample(minority_class,\n",
    "                                    replace=True,\n",
    "                                    n_samples=len(majority_class),\n",
    "                                    random_state=42)\n",
    "    df_train_resampled = pd.concat([majority_class, minority_oversampled])\n",
    "else:\n",
    "    print(\"⚠️ Minority class is empty. Oversampling not performed.\")\n",
    "    df_train_resampled = df_train_combined.copy()\n",
    "\n",
    "print(\"Class distribution after oversampling:\\n\", df_train_resampled['RainTomorrow'].value_counts())\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=df_train_resampled['RainTomorrow'], hue=df_train_resampled['RainTomorrow'], palette='pastel', legend=False)\n",
    "plt.title(\"Class Distribution After Oversampling\", fontsize=14)\n",
    "plt.xlabel(\"Rain Tomorrow (0 = No, 1 = Yes)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks([0, 1], ['No', 'Yes'])\n",
    "plt.savefig('class_distribution_after_oversampling.png')\n",
    "plt.close()\n",
    "\n",
    "# Now, remove outliers from the BALANCED training data\n",
    "features_to_clean = df_train_resampled.drop('RainTomorrow', axis=1)\n",
    "Q1 = features_to_clean.quantile(0.25)\n",
    "Q3 = features_to_clean.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outlier_mask = ((features_to_clean < (Q1 - 1.5 * IQR)) | (features_to_clean > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "cleaned_resampled = df_train_resampled[~outlier_mask]\n",
    "\n",
    "X_train_final = cleaned_resampled.drop('RainTomorrow', axis=1)\n",
    "y_train_final = cleaned_resampled['RainTomorrow']\n",
    "\n",
    "print(\"Final shape after outlier removal:\", cleaned_resampled.shape)\n",
    "print(\"Final class distribution:\\n\", y_train_final.value_counts(normalize=True))\n",
    "\n",
    "# Combine features and target\n",
    "final_cleaned_data = pd.concat([X_train_final, y_train_final], axis=1)\n",
    "\n",
    "print(\"\\n--- Final Cleaned Training Dataset (Preview) ---\")\n",
    "print(final_cleaned_data.head())\n",
    "\n",
    "# Save to CSV\n",
    "final_cleaned_data.to_csv('Cleaned-dataset.csv', index=False)\n",
    "print(\"\\n✅ Final cleaned dataset saved as 'Cleaned-dataset.csv'\")\n",
    "\n",
    "# Model Training and Evaluation\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'MLP Classifier': MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=500, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    model.fit(X_train_final, y_train_final)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    results[model_name] = {\n",
    "        'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Classification Report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "\n",
    "    print(f\"--- {model_name} Evaluation on Test Data ---\")\n",
    "    print(f\"ROC AUC Score: {results[model_name]['ROC_AUC']:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Rain', 'Rain'])\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "    disp.ax_.set_title(f\"Confusion Matrix for {model_name}\")\n",
    "    plt.savefig(f'confusion_matrix_{model_name.replace(\" \", \"_\")}.png')\n",
    "    plt.close(fig)\n",
    "\n",
    "# --- Add Neural Network Model ---\n",
    "print(\"\\n--- Training Neural Network ---\")\n",
    "\n",
    "# Define the Neural Network model\n",
    "nn_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_final.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "nn_model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = nn_model.fit(X_train_final, y_train_final,\n",
    "                        epochs=100,\n",
    "                        batch_size=32,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=0)\n",
    "\n",
    "# Evaluate the Neural Network\n",
    "y_pred_proba_nn = nn_model.predict(X_test_scaled).ravel()\n",
    "y_pred_nn = (y_pred_proba_nn > 0.5).astype(int)\n",
    "\n",
    "results['Neural Network'] = {\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_proba_nn),\n",
    "    'Classification Report': classification_report(y_test, y_pred_nn, output_dict=True)\n",
    "}\n",
    "\n",
    "print(f\"--- Neural Network Evaluation on Test Data ---\")\n",
    "print(f\"ROC AUC Score: {results['Neural Network']['ROC_AUC']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "disp_nn = ConfusionMatrixDisplay(confusion_matrix=cm_nn, display_labels=['No Rain', 'Rain'])\n",
    "fig_nn, ax_nn = plt.subplots(figsize=(6, 6))\n",
    "disp_nn.plot(cmap=plt.cm.Blues, ax=ax_nn)\n",
    "disp_nn.ax_.set_title(f\"Confusion Matrix for Neural Network\")\n",
    "plt.savefig(f'confusion_matrix_Neural_Network.png')\n",
    "plt.close(fig_nn)\n",
    "\n",
    "print(\"\\n--- Step 5: Final Model Comparison Summary ---\")\n",
    "\n",
    "performance_data = []\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    report = metrics['Classification Report']\n",
    "    if '1' in report:\n",
    "        precision_1 = report['1']['precision']\n",
    "        recall_1 = report['1']['recall']\n",
    "        f1_score_1 = report['1']['f1-score']\n",
    "    else:\n",
    "        precision_1 = recall_1 = f1_score_1 = 0.0\n",
    "\n",
    "    performance_data.append({\n",
    "        'Model': model_name,\n",
    "        'ROC_AUC': metrics['ROC_AUC'],\n",
    "        'Precision_1': precision_1,\n",
    "        'Recall_1': recall_1,\n",
    "        'F1-Score_1': f1_score_1\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "performance_df = performance_df.sort_values(by='ROC_AUC', ascending=False)\n",
    "print(performance_df)\n",
    "\n",
    "# Step 3: Plot ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "models['Neural Network'] = nn_model\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'Neural Network':\n",
    "        y_pred_proba = model.predict(X_test_scaled).ravel()\n",
    "    else:\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.savefig('roc_curve_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Step 4: Conclusion\n",
    "print(\"\\n--- Final Conclusion ---\")\n",
    "best_model = performance_df.iloc[0]['Model']\n",
    "print(f\"Based on ROC AUC and F1-Score for the minority class, the best performing model is likely: {best_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
