{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b469de54",
   "metadata": {},
   "source": [
    "Simple Linear Regression (Humidity9am ‚Üí Rainfall)\n",
    "MSE: 1.5253551537449668\n",
    "R¬≤ Score: 0.09107438688803127\n",
    "Multiple Linear Regression (Top Features ‚Üí Rainfall)\n",
    "MSE: 9.409522142573474e-29\n",
    "R¬≤ Score: 1.0\n",
    "Logistic Regression\n",
    "Accuracy: 0.9999258627719909\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     16588\n",
    "         1.0       1.00      1.00      1.00     10389\n",
    "\n",
    "    accuracy                           1.00     26977\n",
    "   macro avg       1.00      1.00      1.00     26977\n",
    "weighted avg       1.00      1.00      1.00     26977\n",
    "Random Forest\n",
    "Accuracy: 1.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     16588\n",
    "         1.0       1.00      1.00      1.00     10389\n",
    "\n",
    "    accuracy                           1.00     26977\n",
    "   macro avg       1.00      1.00      1.00     26977\n",
    "weighted avg       1.00      1.00      1.00     26977\n",
    " SVM\n",
    "Accuracy: 0.9946621195833488\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      0.99      1.00     16588\n",
    "         1.0       0.99      1.00      0.99     10389\n",
    "\n",
    "    accuracy                           0.99     26977\n",
    "   macro avg       0.99      1.00      0.99     26977\n",
    "weighted avg       0.99      0.99      0.99     26977\n",
    "Decision Tree\n",
    "Accuracy: 1.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     16588\n",
    "         1.0       1.00      1.00      1.00     10389\n",
    "\n",
    "    accuracy                           1.00     26977\n",
    "   macro avg       1.00      1.00      1.00     26977\n",
    "weighted avg       1.00      1.00      1.00     26977\n",
    "Neural Network\n",
    "Accuracy: 1.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       1.00      1.00      1.00     16588\n",
    "         1.0       1.00      1.00      1.00     10389\n",
    "\n",
    "    accuracy                           1.00     26977\n",
    "   macro avg       1.00      1.00      1.00     26977\n",
    "weighted avg       1.00      1.00      1.00     26977\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# 1. Load dataset\n",
    "dataset = pd.read_csv('Extracted-dataset.csv')\n",
    "dataset.head()\n",
    "# 2. Encode binary categorical labels\n",
    "dataset['RainToday'] = dataset['RainToday'].map({'No': 0, 'Yes': 1})     # .map() is used to convert categorical values to numerical values .It is better than replace as it avoids the warning and sets the correct data type.\n",
    "dataset['RainTomorrow'] = dataset['RainTomorrow'].map({'No': 0, 'Yes': 1})\n",
    "dataset.head()\n",
    "# 3. Impute object/categorical columns with mode\n",
    "for col in dataset.select_dtypes(include=['object']).columns:\n",
    "    dataset[col] = dataset[col].fillna(dataset[col].mode()[0])\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 4. Label Encode categorical columns\n",
    "lencoders = {}\n",
    "for col in dataset.select_dtypes(include=['object']).columns:\n",
    "    lencoders[col] = LabelEncoder()\n",
    "    dataset[col] = lencoders[col].fit_transform(dataset[col])\n",
    "\n",
    "# 5. Impute numerical columns using Iterative Imputer (MICE)\n",
    "mice_imputer = IterativeImputer()\n",
    "MiceImputed = pd.DataFrame(mice_imputer.fit_transform(dataset), columns=dataset.columns)\n",
    "dataset.head()\n",
    "# 6. Split classes for oversampling BEFORE removing outliers\n",
    "no = MiceImputed[MiceImputed['RainTomorrow'] == 0]\n",
    "yes = MiceImputed[MiceImputed['RainTomorrow'] == 1]\n",
    "print(\"Before Oversampling:\", MiceImputed['RainTomorrow'].value_counts())\n",
    "\n",
    "fig = plt.figure(figsize = (8,5))\n",
    "MiceImputed.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)  \n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) in the Imbalanced Dataset')\n",
    "plt.show()\n",
    "# Oversample the minority class\n",
    "from sklearn.utils import resample\n",
    "if len(yes) > 0:\n",
    "    yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n",
    "    oversampled = pd.concat([no, yes_oversampled])\n",
    "    print(\"After Oversampling:\", oversampled['RainTomorrow'].value_counts())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No samples with RainTomorrow == 1 ‚Äî oversampling not possible.\")\n",
    "    oversampled = MiceImputed.copy()\n",
    "\n",
    "fig = plt.figure(figsize = (8,5))\n",
    "oversampled.RainTomorrow.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
    "plt.title('RainTomorrow Indicator No(0) and Yes(1) after Oversampling (Balanced Dataset)')\n",
    "plt.show()\n",
    "# 7. Now remove outliers (after balancing)\n",
    "Q1 = oversampled.quantile(0.25)\n",
    "Q3 = oversampled.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "cleaned = oversampled[~((oversampled < (Q1 - 1.5 * IQR)) | (oversampled > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"Final shape after outlier removal:\", cleaned.shape)\n",
    "print(\"Final class distribution:\\n\", cleaned['RainTomorrow'].value_counts(normalize=True))\n",
    "# 8. Visualize class balance\n",
    "plt.figure(figsize=(8,5))\n",
    "cleaned['RainTomorrow'].value_counts(normalize=True).plot(kind='bar', color=['skyblue', 'navy'])\n",
    "plt.title('Balanced Dataset After Cleaning & Outlier Removal')\n",
    "plt.xlabel('RainTomorrow (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()\n",
    "# 9. Optional: Heatmap of missing values (should be empty)\n",
    "sns.heatmap(cleaned.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap (Should Be Clean)')\n",
    "plt.show()\n",
    "# 10. Pearson Correlation with RainTomorrow\n",
    "numeric_df = cleaned.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "correlation_with_target = numeric_df.corr()['RainTomorrow'].sort_values(ascending=False)\n",
    "print(correlation_with_target)\n",
    "# 11. Barplot of Correlation\n",
    "sns.barplot(\n",
    "    x=correlation_with_target.drop('RainTomorrow').values,\n",
    "    y=correlation_with_target.drop('RainTomorrow').index                #  .index gives us the row labels ‚Äî which, in this case, are the names of the features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11301723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
    "    roc_curve, auc, mean_squared_error, r2_score\n",
    ")\n",
    "import joblib\n",
    "\n",
    "# === 1. Feature Selection ===\n",
    "correlation_with_target = cleaned.corr()['RainTomorrow'].sort_values(ascending=False)\n",
    "top_features = correlation_with_target[abs(correlation_with_target) > 0.1].drop('RainTomorrow').index.tolist()\n",
    "print(\"Selected Top Features:\", top_features)\n",
    "\n",
    "# === 2. Simple Linear Regression: Humidity9am ‚Üí Rainfall ===\n",
    "print(\"\\nüîπ Simple Linear Regression (Humidity9am ‚Üí Rainfall)\")\n",
    "X_lin = cleaned[['Humidity9am']]\n",
    "y_lin = cleaned['Rainfall']\n",
    "\n",
    "X_train_lin, X_test_lin, y_train_lin, y_test_lin = train_test_split(X_lin, y_lin, test_size=0.2, random_state=42)\n",
    "\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train_lin, y_train_lin)\n",
    "y_pred_lin = lin_model.predict(X_test_lin)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test_lin, y_pred_lin))\n",
    "print(\"R¬≤ Score:\", r2_score(y_test_lin, y_pred_lin))\n",
    "\n",
    "# Plot regression line\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X_test_lin, y_test_lin, color='blue', label='Actual')\n",
    "plt.plot(X_test_lin, y_pred_lin, color='red', linewidth=2, label='Regression Line')\n",
    "plt.xlabel(\"Humidity9am\")\n",
    "plt.ylabel(\"Rainfall\")\n",
    "plt.title(\"Simple Linear Regression: Humidity9am vs Rainfall\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === 3. Multiple Linear Regression: top_features ‚Üí Rainfall ===\n",
    "print(\"\\nüîπ Multiple Linear Regression (Top Features ‚Üí Rainfall)\")\n",
    "X_mlr = cleaned[top_features]\n",
    "y_mlr = cleaned['Rainfall']\n",
    "\n",
    "X_train_mlr, X_test_mlr, y_train_mlr, y_test_mlr = train_test_split(X_mlr, y_mlr, test_size=0.2, random_state=42)\n",
    "\n",
    "mlr_model = LinearRegression()\n",
    "mlr_model.fit(X_train_mlr, y_train_mlr)\n",
    "y_pred_mlr = mlr_model.predict(X_test_mlr)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test_mlr, y_pred_mlr))\n",
    "print(\"R¬≤ Score:\", r2_score(y_test_mlr, y_pred_mlr))\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_test_mlr, y_pred_mlr, alpha=0.6, color='green')\n",
    "plt.plot([y_test_mlr.min(), y_test_mlr.max()], [y_test_mlr.min(), y_test_mlr.max()], 'r--')\n",
    "plt.xlabel(\"Actual Rainfall\")\n",
    "plt.ylabel(\"Predicted Rainfall\")\n",
    "plt.title(\"Multiple Linear Regression: Predicted vs Actual Rainfall\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === 4. Classification Models ===\n",
    "X = cleaned[top_features]\n",
    "y = cleaned['RainTomorrow']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "best_model_name = None\n",
    "best_model_score = 0\n",
    "best_model_object = None\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüìä {name}\")\n",
    "    \n",
    "    if name in ['Random Forest', 'Decision Tree']:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_test_scaled)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    if acc > best_model_score:\n",
    "        best_model_score = acc\n",
    "        best_model_name = name\n",
    "        best_model_object = model\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.title(f\"ROC Curve - {name}\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Feature Importance for Trees\n",
    "    if name in ['Random Forest', 'Decision Tree']:\n",
    "        importance = model.feature_importances_\n",
    "        sorted_idx = importance.argsort()[::-1]\n",
    "        sorted_features = np.array(top_features)[sorted_idx]\n",
    "        sorted_importance = importance[sorted_idx]\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        ax = sns.barplot(x=sorted_importance, y=sorted_features, color='teal')\n",
    "        plt.title(f\"Feature Importance - {name}\")\n",
    "        plt.xlabel(\"Importance Score\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "\n",
    "        for i, (feat, score) in enumerate(zip(sorted_features, sorted_importance)):\n",
    "            ax.text(score + 0.001, i, f\"{score:.4f}\", va=\"center\", fontsize=8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"üîç {name} Feature Importances:\")\n",
    "        for feat, score in zip(sorted_features, sorted_importance):\n",
    "            print(f\"{feat}: {score:.4f}\")\n",
    "\n",
    "# === 5. Save Best Model ===\n",
    "if best_model_object:\n",
    "    filename = f\"{best_model_name.replace(' ', '_')}_best_model.pkl\"\n",
    "    joblib.dump(best_model_object, filename)\n",
    "    print(f\"\\nüíæ Best Model: {best_model_name} with accuracy = {best_model_score:.4f}\")\n",
    "    print(f\"Saved as: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
