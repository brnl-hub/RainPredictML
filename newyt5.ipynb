{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888e63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading and Preprocessing Data ---\n",
      "Original Dataset Shape: (121575, 24)\n",
      "Columns with all missing values: []\n",
      "--- Step 2: Handling Missing Values ---\n",
      "Imputing missing values in column 'Date' with mode value: '2013-03-02'\n",
      "Imputing missing values in column 'Location' with mode value: 'Canberra'\n",
      "Imputing missing values in column 'WindGustDir' with mode value: 'W'\n",
      "Imputing missing values in column 'WindDir9am' with mode value: 'N'\n",
      "Imputing missing values in column 'WindDir3pm' with mode value: 'W'\n",
      "Label encoding categorical columns...\n",
      "Running MICE imputation on numerical features...\n",
      "Shape after imputation: (121575, 22)\n",
      "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
      "0     20.4     25.8       0.0          6.0      12.4          6.0   \n",
      "1     20.9     26.7       0.2          8.0      10.3          3.0   \n",
      "2     22.3     26.3       0.0          3.2       2.0          0.0   \n",
      "3     21.6     22.2       1.2          2.8       0.0          2.0   \n",
      "4     20.4     23.5       2.6          2.2       2.9          2.0   \n",
      "5     20.4     24.4       0.0          3.0       8.7          0.0   \n",
      "\n",
      "   WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  ...  Humidity3pm  \\\n",
      "0           31.0         6.0         7.0          13.0  ...         71.0   \n",
      "1           31.0         5.0         4.0          15.0  ...         77.0   \n",
      "2           35.0         1.0         9.0           6.0  ...         90.0   \n",
      "3           41.0         2.0         2.0          20.0  ...         95.0   \n",
      "4           52.0         2.0         2.0          24.0  ...         86.0   \n",
      "5           48.0         2.0         2.0          30.0  ...         79.0   \n",
      "\n",
      "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
      "0       1014.5       1013.6       3.0       1.0     23.3     24.7        0.0   \n",
      "1       1016.3       1015.5       2.0       5.0     25.0     25.1        0.0   \n",
      "2       1014.6       1014.3       7.0       7.0     24.7     23.8        0.0   \n",
      "3       1016.0       1015.3       8.0       8.0     22.1     21.2        1.0   \n",
      "4       1015.3       1013.7       7.0       7.0     21.8     21.6        1.0   \n",
      "5       1014.5       1012.7       5.0       3.0     21.4     23.3        0.0   \n",
      "\n",
      "   RISK_MM  RainTomorrow  \n",
      "0      0.2           0.0  \n",
      "1      0.0           0.0  \n",
      "2      1.2           1.0  \n",
      "3      2.6           1.0  \n",
      "4      0.0           0.0  \n",
      "5      0.0           0.0  \n",
      "\n",
      "[6 rows x 22 columns]\n",
      "\n",
      "--- Pearson Correlation with 'RainTomorrow' ---\n",
      "RainTomorrow     1.000000\n",
      "RISK_MM          0.502849\n",
      "Humidity3pm      0.445446\n",
      "Cloud3pm         0.424212\n",
      "Cloud9am         0.346735\n",
      "RainToday        0.315456\n",
      "Humidity9am      0.254320\n",
      "Rainfall         0.243046\n",
      "WindGustSpeed    0.235903\n",
      "WindSpeed9am     0.091954\n",
      "WindSpeed3pm     0.090435\n",
      "MinTemp          0.073298\n",
      "WindGustDir      0.062669\n",
      "WindDir3pm       0.042008\n",
      "WindDir9am       0.036469\n",
      "Temp9am         -0.033767\n",
      "Evaporation     -0.139542\n",
      "MaxTemp         -0.163818\n",
      "Temp3pm         -0.197179\n",
      "Pressure3pm     -0.244901\n",
      "Pressure9am     -0.265401\n",
      "Sunshine        -0.480424\n",
      "Name: RainTomorrow, dtype: float64\n",
      "'RISK_MM' feature removed to prevent data leakage.\n",
      "\n",
      "Updated dataset shape: (121575, 21)\n",
      "\n",
      "First 5 rows after removing 'RISK_MM':\n",
      "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
      "0     20.4     25.8       0.0          6.0      12.4          6.0   \n",
      "1     20.9     26.7       0.2          8.0      10.3          3.0   \n",
      "2     22.3     26.3       0.0          3.2       2.0          0.0   \n",
      "3     21.6     22.2       1.2          2.8       0.0          2.0   \n",
      "4     20.4     23.5       2.6          2.2       2.9          2.0   \n",
      "\n",
      "   WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  ...  Humidity9am  \\\n",
      "0           31.0         6.0         7.0          13.0  ...         84.0   \n",
      "1           31.0         5.0         4.0          15.0  ...         79.0   \n",
      "2           35.0         1.0         9.0           6.0  ...         87.0   \n",
      "3           41.0         2.0         2.0          20.0  ...         92.0   \n",
      "4           52.0         2.0         2.0          24.0  ...         86.0   \n",
      "\n",
      "   Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
      "0         71.0       1014.5       1013.6       3.0       1.0     23.3   \n",
      "1         77.0       1016.3       1015.5       2.0       5.0     25.0   \n",
      "2         90.0       1014.6       1014.3       7.0       7.0     24.7   \n",
      "3         95.0       1016.0       1015.3       8.0       8.0     22.1   \n",
      "4         86.0       1015.3       1013.7       7.0       7.0     21.8   \n",
      "\n",
      "   Temp3pm  RainToday  RainTomorrow  \n",
      "0     24.7        0.0           0.0  \n",
      "1     25.1        0.0           0.0  \n",
      "2     23.8        0.0           1.0  \n",
      "3     21.2        1.0           1.0  \n",
      "4     21.6        1.0           0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Original Class Distribution:\n",
      " RainTomorrow\n",
      "0.0    0.773901\n",
      "1.0    0.226099\n",
      "Name: proportion, dtype: float64\n",
      "Training Set Class Distribution:\n",
      " RainTomorrow\n",
      "0.0    0.773907\n",
      "1.0    0.226093\n",
      "Name: proportion, dtype: float64\n",
      "Testing Set Class Distribution:\n",
      " RainTomorrow\n",
      "0.0    0.773888\n",
      "1.0    0.226112\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Step 3: Oversampling and Handling Outliers on Training Data ---\n",
      "Class distribution after oversampling:\n",
      " RainTomorrow\n",
      "0.0    65861\n",
      "1.0    65861\n",
      "Name: count, dtype: int64\n",
      "Final shape after outlier removal: (103013, 21)\n",
      "Final class distribution:\n",
      " RainTomorrow\n",
      "0.0    0.561822\n",
      "1.0    0.438178\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Final Cleaned Training Dataset (Preview) ---\n",
      "     MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustDir  \\\n",
      "2   0.098553  1.075629  -0.27977     0.652595  0.220493    -1.700321   \n",
      "3  -0.304344  1.020181  -0.27977    -0.291837  0.645181    -0.207745   \n",
      "4  -2.396309 -1.045242  -0.27977    -0.183345  0.786743    -1.273871   \n",
      "7  -0.164879  0.507291  -0.27977    -0.508822 -0.062633    -0.207745   \n",
      "10 -1.342579 -0.851175  -0.27977    -0.605565  0.588556    -0.634196   \n",
      "\n",
      "    WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  ...  Humidity9am  \\\n",
      "2        0.197676   -1.550710    0.025917      0.869946  ...    -1.145714   \n",
      "3       -0.246720   -0.887302   -0.405110     -1.624024  ...     1.625590   \n",
      "4        0.716137    0.439515    0.241430     -0.150315  ...    -0.779692   \n",
      "7        1.160533   -0.223893   -0.189596     -0.150315  ...    -1.302580   \n",
      "10      -1.505842   -1.329574   -0.620623     -0.377039  ...    -0.465960   \n",
      "\n",
      "    Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm   Temp9am  \\\n",
      "2     -1.000797    -0.213519    -0.497136  0.229074  1.468046  0.767738   \n",
      "3     -1.194324     0.731207     0.571186 -0.182168 -0.733883 -0.650594   \n",
      "4     -1.726524     1.890643     1.639507 -1.342181 -1.886009 -1.540824   \n",
      "7     -1.339469    -0.328031    -0.424952  0.229074  0.629532  0.511231   \n",
      "10    -0.613742     1.890643     1.798311 -1.734994 -0.924871 -0.907101   \n",
      "\n",
      "     Temp3pm  RainToday  RainTomorrow  \n",
      "2   1.224938  -0.541299           0.0  \n",
      "3   1.182580  -0.541299           0.0  \n",
      "4  -0.991803  -0.541299           0.0  \n",
      "7   0.660163  -0.541299           0.0  \n",
      "10 -0.794132  -0.541299           0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "✅ Final cleaned dataset saved as 'Cleaned-dataset.csv'\n",
      "\n",
      "--- Training Logistic Regression ---\n",
      "--- Logistic Regression Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.8807\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86     28226\n",
      "         1.0       0.54      0.80      0.65      8247\n",
      "\n",
      "    accuracy                           0.80     36473\n",
      "   macro avg       0.74      0.80      0.75     36473\n",
      "weighted avg       0.84      0.80      0.81     36473\n",
      "\n",
      "\n",
      "--- Training Random Forest ---\n",
      "--- Random Forest Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.9157\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92     28226\n",
      "         1.0       0.77      0.63      0.69      8247\n",
      "\n",
      "    accuracy                           0.87     36473\n",
      "   macro avg       0.83      0.79      0.80     36473\n",
      "weighted avg       0.87      0.87      0.87     36473\n",
      "\n",
      "\n",
      "--- Training MLP Classifier ---\n",
      "--- MLP Classifier Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.9100\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.91      0.91     28226\n",
      "         1.0       0.70      0.73      0.71      8247\n",
      "\n",
      "    accuracy                           0.87     36473\n",
      "   macro avg       0.81      0.82      0.81     36473\n",
      "weighted avg       0.87      0.87      0.87     36473\n",
      "\n",
      "\n",
      "--- Training XGBoost ---\n",
      "--- XGBoost Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.9144\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90     28226\n",
      "         1.0       0.64      0.79      0.70      8247\n",
      "\n",
      "    accuracy                           0.85     36473\n",
      "   macro avg       0.79      0.83      0.80     36473\n",
      "weighted avg       0.87      0.85      0.86     36473\n",
      "\n",
      "\n",
      "--- Training IMPROVED Neural Network ---\n",
      "\u001b[1m1140/1140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "--- Improved Neural Network Evaluation on Test Data ---\n",
      "ROC AUC Score: 0.9419\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91     28226\n",
      "         1.0       0.65      0.87      0.74      8247\n",
      "\n",
      "    accuracy                           0.86     36473\n",
      "   macro avg       0.80      0.86      0.82     36473\n",
      "weighted avg       0.89      0.86      0.87     36473\n",
      "\n",
      "\n",
      "--- Step 5: Final Model Comparison Summary ---\n",
      "                     Model   ROC_AUC  Precision_1  Recall_1  F1-Score_1\n",
      "4  Improved Neural Network  0.941947          0.0       0.0         0.0\n",
      "1            Random Forest  0.915696          0.0       0.0         0.0\n",
      "3                  XGBoost  0.914377          0.0       0.0         0.0\n",
      "2           MLP Classifier  0.909999          0.0       0.0         0.0\n",
      "0      Logistic Regression  0.880681          0.0       0.0         0.0\n",
      "\u001b[1m1140/1140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step\n",
      "\n",
      "--- Final Conclusion ---\n",
      "Based on ROC AUC and F1-Score for the minority class, the best performing model is likely: Improved Neural Network\n"
     ]
    }
   ],
   "source": [
    "# The Python script for a rainfall prediction model with detailed comments.\n",
    "# This code is a complete machine learning pipeline, covering everything from data loading and cleaning\n",
    "# to model training and evaluation.\n",
    "\n",
    "# --- Step 0: Library Imports ---\n",
    "# Import necessary libraries for data manipulation, visualization, preprocessing, and modeling.\n",
    "import pandas as pd  # Used for data manipulation and analysis, primarily for DataFrames.\n",
    "import seaborn as sns  # A high-level library for drawing attractive statistical graphics.\n",
    "import matplotlib.pyplot as plt  # A comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  # `LabelEncoder` converts categorical text labels into numerical format, while `StandardScaler` standardizes features by removing the mean and scaling to unit variance.\n",
    "from sklearn.experimental import enable_iterative_imputer  # This is needed to enable the experimental `IterativeImputer` from scikit-learn.\n",
    "from sklearn.impute import IterativeImputer  # `IterativeImputer` (MICE) is an advanced technique for imputing missing values.\n",
    "from sklearn.model_selection import train_test_split  # A utility to split arrays or matrices into random train and test subsets.\n",
    "from sklearn.utils import resample  # Used here to oversample the minority class to handle class imbalance.\n",
    "from sklearn.linear_model import LogisticRegression  # A linear model for binary classification, serving as a good baseline.\n",
    "from sklearn.ensemble import RandomForestClassifier  # An ensemble method that builds multiple decision trees.\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve  # Metrics and visualization tools to evaluate model performance.\n",
    "from sklearn.neural_network import MLPClassifier  # A simple Multi-layer Perceptron (neural network).\n",
    "from xgboost import XGBClassifier  # A powerful and highly efficient gradient boosting library.\n",
    "import tensorflow as tf  # The core deep learning library.\n",
    "from tensorflow.keras.models import Sequential  # A way to build a neural network layer by layer.\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input  # `Dense` is a standard fully-connected layer, `Dropout` randomly sets a fraction of input units to 0 to prevent overfitting, and `Input` is used to specify the shape of the input data.\n",
    "from tensorflow.keras.regularizers import l2  # L2 regularization is used to penalize large weights and prevent overfitting.\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # A callback to stop training when a monitored metric has stopped improving.\n",
    "\n",
    "print(\"--- Step 1: Loading and Preprocessing Data ---\")\n",
    "try:\n",
    "    # Attempt to load the dataset. The code will execute this block.\n",
    "    dataset = pd.read_csv('Extracted-dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    # If the file is not found, this block will be executed,\n",
    "    # printing an error message and exiting the script gracefully.\n",
    "    print(\"Error: 'Extracted-dataset.csv' not found. Please check the file path.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Original Dataset Shape:\", dataset.shape)\n",
    "\n",
    "# --- STEP 1.1: Encode binary target/label columns ---\n",
    "# Convert the 'Yes'/'No' string labels in 'RainToday' and 'RainTomorrow' to 1/0 for model training.\n",
    "dataset['RainToday'] = dataset['RainToday'].map({'No': 0, 'Yes': 1})\n",
    "dataset['RainTomorrow'] = dataset['RainTomorrow'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# Check for columns that are entirely empty.\n",
    "fully_missing_cols = dataset.columns[dataset.isnull().all()]\n",
    "print(\"Columns with all missing values:\", fully_missing_cols.tolist())\n",
    "\n",
    "# --- Step 2: Handling Missing Values ---\n",
    "print(\"--- Step 2: Handling Missing Values ---\")\n",
    "\n",
    "# Separate columns into categorical (object) and numerical (float/int).\n",
    "categorical_cols = dataset.select_dtypes(include=['object']).columns\n",
    "numerical_cols = dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "columns_to_impute = [col for col in dataset.columns if col not in ['Date', 'Location']]\n",
    "\n",
    "# Step 2.1: Impute categorical columns with mode\n",
    "# Iterate through each categorical column.\n",
    "for col in categorical_cols:\n",
    "    # Find the most frequent value (mode) in the column.\n",
    "    mode_value = dataset[col].mode()[0]\n",
    "    print(f\"Imputing missing values in column '{col}' with mode value: '{mode_value}'\")\n",
    "    # Fill any missing values (NaN) with the calculated mode.\n",
    "    dataset[col] = dataset[col].fillna(mode_value)\n",
    "\n",
    "# Step 2.2: Label Encode categorical columns\n",
    "print(\"Label encoding categorical columns...\")\n",
    "lencoders = {}  # Create an empty dictionary to store each LabelEncoder instance.\n",
    "# Iterate through each categorical column again.\n",
    "for col in categorical_cols:\n",
    "    lencoders[col] = LabelEncoder()  # Create a new LabelEncoder for the column.\n",
    "    # Fit the encoder on the data and transform the column.\n",
    "    dataset[col] = lencoders[col].fit_transform(dataset[col])\n",
    "\n",
    "# Prepare a copy of the data for MICE imputation, excluding 'Date' and 'Location' as they are not needed for this process.\n",
    "dataset_for_mice = dataset[columns_to_impute].copy()\n",
    "\n",
    "# Step 2.3: Impute numerical columns using Iterative Imputer (MICE)\n",
    "print(\"Running MICE imputation on numerical features...\")\n",
    "# Initialize the MICE imputer with a max_iter and random_state for reproducibility.\n",
    "mice_imputer = IterativeImputer(max_iter=50, random_state=42)\n",
    "# Fit the imputer on the data and transform it. This returns a NumPy array.\n",
    "dataset_imputed_array = mice_imputer.fit_transform(dataset_for_mice)\n",
    "# Convert the imputed array back into a pandas DataFrame, preserving the column names.\n",
    "dataset_imputed = pd.DataFrame(dataset_imputed_array, columns=dataset_for_mice.columns)\n",
    "\n",
    "print(\"Shape after imputation:\", dataset_imputed.shape)\n",
    "print(dataset_imputed.head(6))\n",
    "\n",
    "# --- Step 3: Exploratory Data Analysis (EDA) ---\n",
    "# Step 1: Keep only numeric columns for correlation analysis.\n",
    "numeric_df = dataset_imputed.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Step 2: Calculate the Pearson correlation of each numeric column with the 'RainTomorrow' target.\n",
    "correlation_with_target = numeric_df.corr()['RainTomorrow'].sort_values(ascending=False)\n",
    "\n",
    "# Step 3: Print and plot correlation values.\n",
    "print(\"\\n--- Pearson Correlation with 'RainTomorrow' ---\")\n",
    "print(correlation_with_target)\n",
    "\n",
    "# Create a figure for the plot.\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Create a bar plot using seaborn. We drop 'RainTomorrow' itself from the plot as it would have a perfect correlation of 1.\n",
    "sns.barplot(\n",
    "    x=correlation_with_target.drop('RainTomorrow').values,\n",
    "    y=correlation_with_target.drop('RainTomorrow').index\n",
    ")\n",
    "plt.title(\"Pearson Correlation with 'RainTomorrow'\")\n",
    "plt.xlabel(\"Correlation Coefficient\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.tight_layout()  # Adjusts plot parameters for a tight layout.\n",
    "plt.savefig('correlation_barplot.png')  # Save the plot to a file.\n",
    "plt.close()  # Close the plot to free up memory.\n",
    "\n",
    "# --- Step 4: Preparing Data for Modeling ---\n",
    "# Make a copy of the imputed dataset.\n",
    "data = dataset_imputed.copy()\n",
    "\n",
    "# Remove 'RISK_MM' to prevent data leakage.\n",
    "if 'RISK_MM' in data.columns:\n",
    "    data.drop('RISK_MM', axis=1, inplace=True)\n",
    "    print(\"'RISK_MM' feature removed to prevent data leakage.\")\n",
    "else:\n",
    "    print(\"'RISK_MM' already removed or not present.\")\n",
    "\n",
    "print(\"\\nUpdated dataset shape:\", data.shape)\n",
    "print(\"\\nFirst 5 rows after removing 'RISK_MM':\")\n",
    "print(data.head())\n",
    "\n",
    "# Define features (X) and target (y).\n",
    "X = data.drop('RainTomorrow', axis=1)  # All columns except the target.\n",
    "y = data['RainTomorrow']  # The target variable.\n",
    "\n",
    "# Split the data into training (70%) and testing (30%) sets.\n",
    "# `stratify=y` ensures that the class distribution is maintained in both sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Standardize the numerical features.         improve training speed and stability, and to make sure all features contribute fairly to a machine learning model \n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler on the training data and transform it.\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "# Use the *same* scaler to transform the test data. Do not fit again.\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "print(\"Original Class Distribution:\\n\", y.value_counts(normalize=True))\n",
    "print(\"Training Set Class Distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Testing Set Class Distribution:\\n\", y_test.value_counts(normalize=True))\n",
    "\n",
    "# Plot the class distribution before oversampling.\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y_train_df['RainTomorrow'], hue=y_train_df['RainTomorrow'], palette='pastel', legend=False)\n",
    "plt.title(\"Class Distribution Before Oversampling\")\n",
    "plt.xlabel(\"RainTomorrow (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.savefig('class_distribution_before_oversampling.png')\n",
    "plt.close()\n",
    "\n",
    "# --- Step 5: Oversampling and Handling Outliers on Training Data ---\n",
    "print(\"\\n--- Step 3: Oversampling and Handling Outliers on Training Data ---\")\n",
    "# Combine the scaled training features and the training labels into a single DataFrame.\n",
    "df_train_combined = pd.concat([X_train_scaled, y_train.reset_index(drop=True)], axis=1)\n",
    "# Separate the majority (0) and minority (1) classes.\n",
    "minority_class = df_train_combined[df_train_combined['RainTomorrow'] == 1]\n",
    "majority_class = df_train_combined[df_train_combined['RainTomorrow'] == 0]\n",
    "\n",
    "# Perform oversampling on the minority class.\n",
    "if not minority_class.empty:\n",
    "    # Resample the minority class with replacement to match the size of the majority class.\n",
    "    minority_oversampled = resample(minority_class,\n",
    "                                    replace=True,\n",
    "                                    n_samples=len(majority_class),\n",
    "                                    random_state=42)\n",
    "    # Combine the resampled minority class with the original majority class.\n",
    "    df_train_resampled = pd.concat([majority_class, minority_oversampled])\n",
    "else:\n",
    "    print(\"⚠️ Minority class is empty. Oversampling not performed.\")\n",
    "    df_train_resampled = df_train_combined.copy()\n",
    "\n",
    "print(\"Class distribution after oversampling:\\n\", df_train_resampled['RainTomorrow'].value_counts())\n",
    "# Plot the new balanced class distribution.\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=df_train_resampled['RainTomorrow'], hue=df_train_resampled['RainTomorrow'], palette='pastel', legend=False)\n",
    "plt.title(\"Class Distribution After Oversampling\", fontsize=14)\n",
    "plt.xlabel(\"Rain Tomorrow (0 = No, 1 = Yes)\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.xticks([0, 1], ['No', 'Yes'])\n",
    "plt.savefig('class_distribution_after_oversampling.png')\n",
    "plt.close()\n",
    "\n",
    "# Outlier removal using the Interquartile Range (IQR) method.\n",
    "features_to_clean = df_train_resampled.drop('RainTomorrow', axis=1)\n",
    "Q1 = features_to_clean.quantile(0.25)\n",
    "Q3 = features_to_clean.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Create a mask to identify rows with outliers.\n",
    "outlier_mask = ((features_to_clean < (Q1 - 1.5 * IQR)) | (features_to_clean > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "# Keep only the rows that are NOT outliers.\n",
    "cleaned_resampled = df_train_resampled[~outlier_mask]\n",
    "\n",
    "# Separate the final clean features and target for training.\n",
    "X_train_final = cleaned_resampled.drop('RainTomorrow', axis=1)\n",
    "y_train_final = cleaned_resampled['RainTomorrow']\n",
    "\n",
    "print(\"Final shape after outlier removal:\", cleaned_resampled.shape)\n",
    "print(\"Final class distribution:\\n\", y_train_final.value_counts(normalize=True))\n",
    "\n",
    "final_cleaned_data = pd.concat([X_train_final, y_train_final], axis=1)\n",
    "print(\"\\n--- Final Cleaned Training Dataset (Preview) ---\")\n",
    "print(final_cleaned_data.head())\n",
    "final_cleaned_data.to_csv('Cleaned-dataset.csv', index=False)\n",
    "print(\"\\n✅ Final cleaned dataset saved as 'Cleaned-dataset.csv'\")\n",
    "\n",
    "# --- Step 6: Model Training and Evaluation ---\n",
    "# Initialize the list of models to train.\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'MLP Classifier': MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=500, random_state=42),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "}\n",
    "results = {}  # Dictionary to store performance results for each model.\n",
    "\n",
    "# Loop through each model in the dictionary.\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "    # Train the model using the final cleaned training data.\n",
    "    model.fit(X_train_final, y_train_final)\n",
    "\n",
    "    # Make predictions on the scaled test data.\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    # Get probability scores for the ROC AUC calculation.\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Store the evaluation metrics.\n",
    "    results[model_name] = {\n",
    "        'ROC_AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Classification Report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "\n",
    "    # Print the evaluation results.\n",
    "    print(f\"--- {model_name} Evaluation on Test Data ---\")\n",
    "    print(f\"ROC AUC Score: {results[model_name]['ROC_AUC']:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Generate and save a confusion matrix plot.\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Rain', 'Rain'])\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "    disp.ax_.set_title(f\"Confusion Matrix for {model_name}\")\n",
    "    plt.savefig(f'confusion_matrix_{model_name.replace(\" \", \"_\")}.png')\n",
    "    plt.close(fig)\n",
    "\n",
    "# --- Step 7: Add IMPROVED Neural Network Model ---\n",
    "print(\"\\n--- Training IMPROVED Neural Network ---\")\n",
    "\n",
    "# Define the Neural Network model with L2 regularization and Dropout.\n",
    "nn_model = Sequential([\n",
    "    Input(shape=(X_train_final.shape[1],)),  # Input layer specifying the number of features.\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),  # First hidden layer with 128 neurons, ReLU activation, and L2 regularization.\n",
    "    Dropout(0.3),  # Dropout layer to prevent overfitting. 30% of neurons will be \"dropped out\" during each training step.\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),  # Second hidden layer with 64 neurons, ReLU, and L2.\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),  # Third hidden layer with 32 neurons, ReLU, and L2.\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Output layer with a single neuron and a sigmoid activation for binary classification (outputs a probability between 0 and 1).\n",
    "])\n",
    "\n",
    "# Compile the model with an optimizer, loss function, and metrics.\n",
    "nn_model.compile(optimizer='adam',  # The Adam optimizer is a popular choice for deep learning.\n",
    "                 loss='binary_crossentropy',  # The appropriate loss function for binary classification.\n",
    "                 metrics=[tf.keras.metrics.AUC(name='auc')])  # We'll monitor the Area Under the Curve (AUC) during training.\n",
    "\n",
    "# Define early stopping callback.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model.\n",
    "history = nn_model.fit(X_train_final, y_train_final,\n",
    "                        epochs=200,  # The number of times to iterate over the entire dataset.\n",
    "                        batch_size=32,  # The number of samples per gradient update.\n",
    "                        validation_split=0.2,  # Use 20% of the training data for validation.\n",
    "                        callbacks=[early_stopping],  # Use the early stopping callback.\n",
    "                        verbose=0)  # Do not print training progress to the console.\n",
    "\n",
    "# Evaluate the Neural Network.\n",
    "# Predict probabilities on the test set. `.ravel()` flattens the output array.\n",
    "y_pred_proba_nn = nn_model.predict(X_test_scaled).ravel()\n",
    "# Convert probabilities to a binary prediction (0 or 1) based on a threshold of 0.5.\n",
    "y_pred_nn = (y_pred_proba_nn > 0.5).astype(int)\n",
    "\n",
    "# Store the NN model's results.\n",
    "results['Improved Neural Network'] = {\n",
    "    'ROC_AUC': roc_auc_score(y_test, y_pred_proba_nn),\n",
    "    'Classification Report': classification_report(y_test, y_pred_nn, output_dict=True)\n",
    "}\n",
    "\n",
    "print(f\"--- Improved Neural Network Evaluation on Test Data ---\")\n",
    "print(f\"ROC AUC Score: {results['Improved Neural Network']['ROC_AUC']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "\n",
    "# Generate and save a confusion matrix for the neural network.\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "disp_nn = ConfusionMatrixDisplay(confusion_matrix=cm_nn, display_labels=['No Rain', 'Rain'])\n",
    "fig_nn, ax_nn = plt.subplots(figsize=(6, 6))\n",
    "disp_nn.plot(cmap=plt.cm.Blues, ax=ax_nn)\n",
    "disp_nn.ax_.set_title(f\"Confusion Matrix for Improved Neural Network\")\n",
    "plt.savefig(f'confusion_matrix_Improved_Neural_Network.png')\n",
    "plt.close(fig_nn)\n",
    "\n",
    "# --- Step 8: Final Model Comparison Summary ---\n",
    "print(\"\\n--- Step 5: Final Model Comparison Summary ---\")\n",
    "\n",
    "performance_data = []\n",
    "\n",
    "# Loop through the stored results to create a summary DataFrame.\n",
    "for model_name, metrics in results.items():\n",
    "    report = metrics['Classification Report']\n",
    "    # Check if class '1' (Rain) exists in the report.\n",
    "    if '1' in report:\n",
    "        precision_1 = report['1']['precision']\n",
    "        recall_1 = report['1']['recall']\n",
    "        f1_score_1 = report['1']['f1-score']\n",
    "    else:\n",
    "        # If no positive predictions were made, set metrics to 0.\n",
    "        precision_1 = recall_1 = f1_score_1 = 0.0\n",
    "\n",
    "    # Append the results to the list.\n",
    "    performance_data.append({\n",
    "        'Model': model_name,\n",
    "        'ROC_AUC': metrics['ROC_AUC'],\n",
    "        'Precision_1': precision_1,\n",
    "        'Recall_1': recall_1,\n",
    "        'F1-Score_1': f1_score_1\n",
    "    })\n",
    "\n",
    "# Create the final DataFrame and sort it by ROC AUC score.\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "performance_df = performance_df.sort_values(by='ROC_AUC', ascending=False)\n",
    "print(performance_df)\n",
    "\n",
    "# Plot ROC curves for all models.\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Add the Keras NN model to the models dictionary for easy plotting.\n",
    "models['Improved Neural Network'] = nn_model\n",
    "\n",
    "# Loop through all models to plot their ROC curves.\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'Improved Neural Network':\n",
    "        # For the Keras model, predict probabilities directly.\n",
    "        y_pred_proba = model.predict(X_test_scaled).ravel()\n",
    "    else:\n",
    "        # For scikit-learn models, use `predict_proba`.\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Calculate the False Positive Rate (FPR), True Positive Rate (TPR), and thresholds.\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    # Calculate the ROC AUC score.\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    # Plot the curve.\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "# Plot the diagonal line representing a random guess.\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.savefig('roc_curve_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# --- Step 9: Final Conclusion ---\n",
    "print(\"\\n--- Final Conclusion ---\")\n",
    "# Get the name of the best-performing model from the sorted DataFrame.\n",
    "best_model = performance_df.iloc[0]['Model']\n",
    "print(f\"Based on ROC AUC and F1-Score for the minority class, the best performing model is likely: {best_model}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
