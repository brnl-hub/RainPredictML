{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# 1. Load dataset\n",
    "dataset = pd.read_csv('Extracted-dataset.csv')\n",
    "\n",
    "# 2. Encode binary categorical labels (use map to avoid FutureWarning)\n",
    "dataset['RainToday'] = dataset['RainToday'].map({'No': 0, 'Yes': 1})\n",
    "dataset['RainTomorrow'] = dataset['RainTomorrow'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "# 3. Impute object/categorical columns with mode\n",
    "for col in dataset.select_dtypes(include=['object']).columns:\n",
    "    dataset[col] = dataset[col].fillna(dataset[col].mode()[0])\n",
    "\n",
    "# 4. Label Encode categorical columns\n",
    "lencoders = {}\n",
    "for col in dataset.select_dtypes(include=['object']).columns:\n",
    "    lencoders[col] = LabelEncoder()\n",
    "    dataset[col] = lencoders[col].fit_transform(dataset[col])\n",
    "\n",
    "# 5. Impute numerical columns using Iterative Imputer (MICE)\n",
    "mice_imputer = IterativeImputer()\n",
    "MiceImputed = pd.DataFrame(mice_imputer.fit_transform(dataset), columns=dataset.columns)\n",
    "\n",
    "# 6. Split classes for oversampling BEFORE removing outliers\n",
    "no = MiceImputed[MiceImputed['RainTomorrow'] == 0]\n",
    "yes = MiceImputed[MiceImputed['RainTomorrow'] == 1]\n",
    "\n",
    "# Oversample the minority class\n",
    "if len(yes) > 0:\n",
    "    yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n",
    "    oversampled = pd.concat([no, yes_oversampled])\n",
    "    print(\"After Oversampling:\", oversampled['RainTomorrow'].value_counts())\n",
    "else:\n",
    "    print(\"âš  No samples with RainTomorrow == 1 â€” oversampling not possible.\")\n",
    "    oversampled = MiceImputed.copy()\n",
    "\n",
    "# 7. Now remove outliers (after balancing)\n",
    "Q1 = oversampled.quantile(0.25)\n",
    "Q3 = oversampled.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "cleaned = oversampled[~((oversampled < (Q1 - 1.5 * IQR)) | (oversampled > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"Final shape after outlier removal:\", cleaned.shape)\n",
    "print(\"Final class distribution:\\n\", cleaned['RainTomorrow'].value_counts(normalize=True))\n",
    "\n",
    "# 8. Visualize class balance\n",
    "plt.figure(figsize=(8,5))\n",
    "cleaned['RainTomorrow'].value_counts(normalize=True).plot(kind='bar', color=['skyblue', 'navy'])\n",
    "plt.title('Balanced Dataset After Cleaning & Outlier Removal')\n",
    "plt.xlabel('RainTomorrow (0 = No, 1 = Yes)')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()\n",
    "\n",
    "# 9. Optional: Heatmap of missing values (should be empty)\n",
    "sns.heatmap(cleaned.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap (Should Be Clean)')\n",
    "plt.show()\n",
    "\n",
    "# 10. Pearson Correlation with RainTomorrow\n",
    "numeric_df = cleaned.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "correlation_with_target = numeric_df.corr()['RainTomorrow'].sort_values(ascending=False)\n",
    "print(correlation_with_target)\n",
    "\n",
    "# 11. Barplot of Correlation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=correlation_with_target.drop('RainTomorrow').values,\n",
    "            y=correlation_with_target.drop('RainTomorrow').index,\n",
    "            palette='coolwarm')\n",
    "plt.title('Correlation of Features with RainTomorrow')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === 1. FEATURE SELECTION (optional) ===\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = cleaned.corr()\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Choose features most correlated with RainTomorrow (excluding it)\n",
    "target_corr = corr['RainTomorrow'].drop('RainTomorrow')\n",
    "top_features = target_corr[abs(target_corr) > 0.1].index.tolist()  # You can change 0.1 to any threshold\n",
    "print(\"Selected Features for Classification:\", top_features)\n",
    "\n",
    "# === 2. REGRESSION MODELS (Rainfall as target) ===\n",
    "\n",
    "## SIMPLE LINEAR REGRESSION: Humidity9am â†’ Rainfall\n",
    "X_lin = cleaned[['Humidity9am']]\n",
    "y_lin = cleaned['Rainfall']\n",
    "\n",
    "X_train_lin, X_test_lin, y_train_lin, y_test_lin = train_test_split(X_lin, y_lin, test_size=0.2, random_state=42)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_lin, y_train_lin)\n",
    "y_pred_lin = lin_reg.predict(X_test_lin)\n",
    "\n",
    "print(\"\\nâœ… Simple Linear Regression\")\n",
    "print(\"MSE:\", mean_squared_error(y_test_lin, y_pred_lin))\n",
    "print(\"RÂ²:\", r2_score(y_test_lin, y_pred_lin))\n",
    "\n",
    "## MULTIPLE LINEAR REGRESSION: top_features â†’ Rainfall\n",
    "X_mlr = cleaned[top_features]\n",
    "y_mlr = cleaned['Rainfall']\n",
    "\n",
    "X_train_mlr, X_test_mlr, y_train_mlr, y_test_mlr = train_test_split(X_mlr, y_mlr, test_size=0.2, random_state=42)\n",
    "\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(X_train_mlr, y_train_mlr)\n",
    "y_pred_mlr = mlr.predict(X_test_mlr)\n",
    "\n",
    "print(\"\\nâœ… Multiple Linear Regression\")\n",
    "print(\"MSE:\", mean_squared_error(y_test_mlr, y_pred_mlr))\n",
    "print(\"RÂ²:\", r2_score(y_test_mlr, y_pred_mlr))\n",
    "\n",
    "# === 3. CLASSIFICATION MODELS (RainTomorrow as target) ===\n",
    "\n",
    "# Define input features and target\n",
    "X = cleaned[top_features]  # You can use cleaned.drop(columns='RainTomorrow') for full features\n",
    "y = cleaned['RainTomorrow']\n",
    "\n",
    "# Split & scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === MODEL DEFINITIONS ===\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# === MODEL TRAINING AND EVALUATION ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸ“Š {name}\")\n",
    "    \n",
    "    # Use scaled data for non-tree models\n",
    "    if name in ['Random Forest', 'Decision Tree']:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669130de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, mean_squared_error, r2_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    ConfusionMatrixDisplay, roc_curve, auc\n",
    ")\n",
    "import joblib\n",
    "\n",
    "# === LOAD OR SIMULATE DATA ===\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Simulate data (replace with your cleaned dataset)\n",
    "X_dummy, y_dummy = make_classification(n_samples=3000, n_features=10, n_informative=6, n_classes=2, random_state=42)\n",
    "cleaned = pd.DataFrame(X_dummy, columns=[f'Feature{i}' for i in range(X_dummy.shape[1])])\n",
    "cleaned['Humidity9am'] = np.random.rand(3000) * 100\n",
    "cleaned['Rainfall'] = np.random.rand(3000) * 10\n",
    "cleaned['RainTomorrow'] = y_dummy\n",
    "\n",
    "# === 1. FEATURE SELECTION ===\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = cleaned.corr()\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "target_corr = corr['RainTomorrow'].drop('RainTomorrow')\n",
    "top_features = target_corr[abs(target_corr) > 0.1].index.tolist()\n",
    "print(\"Selected Features:\", top_features)\n",
    "\n",
    "# === 2. SIMPLE LINEAR REGRESSION ===\n",
    "print(\"\\nðŸ”¹ Simple Linear Regression (Humidity9am â†’ Rainfall)\")\n",
    "X_lin = cleaned[['Humidity9am']]\n",
    "y_lin = cleaned['Rainfall']\n",
    "X_train_lin, X_test_lin, y_train_lin, y_test_lin = train_test_split(X_lin, y_lin, test_size=0.2, random_state=42)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_lin, y_train_lin)\n",
    "y_pred_lin = lin_reg.predict(X_test_lin)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test_lin, y_pred_lin))\n",
    "print(\"RÂ²:\", r2_score(y_test_lin, y_pred_lin))\n",
    "\n",
    "# === 3. MULTIPLE LINEAR REGRESSION ===\n",
    "print(\"\\nðŸ”¹ Multiple Linear Regression (Top Features â†’ Rainfall)\")\n",
    "X_mlr = cleaned[top_features]\n",
    "y_mlr = cleaned['Rainfall']\n",
    "X_train_mlr, X_test_mlr, y_train_mlr, y_test_mlr = train_test_split(X_mlr, y_mlr, test_size=0.2, random_state=42)\n",
    "\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(X_train_mlr, y_train_mlr)\n",
    "y_pred_mlr = mlr.predict(X_test_mlr)\n",
    "\n",
    "print(\"MSE:\", mean_squared_error(y_test_mlr, y_pred_mlr))\n",
    "print(\"RÂ²:\", r2_score(y_test_mlr, y_pred_mlr))\n",
    "\n",
    "# === 4. CLASSIFICATION MODELS ===\n",
    "X = cleaned[top_features]\n",
    "y = cleaned['RainTomorrow']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Neural Network\": MLPClassifier(hidden_layer_sizes=(50, 30), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# === 5. EVALUATION LOOP ===\n",
    "best_model_name = None\n",
    "best_model_score = 0\n",
    "best_model_object = None\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸ“Š {name}\")\n",
    "\n",
    "    if name in ['Random Forest', 'Decision Tree']:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            y_proba = model.decision_function(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save best model\n",
    "    if accuracy > best_model_score:\n",
    "        best_model_score = accuracy\n",
    "        best_model_name = name\n",
    "        best_model_object = model\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix: {name}\")\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve: {name}')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importance (trees only)\n",
    "    if name in ['Random Forest', 'Decision Tree']:\n",
    "        importance = model.feature_importances_\n",
    "        sorted_idx = np.argsort(importance)[::-1]\n",
    "        sorted_features = np.array(top_features)[sorted_idx]\n",
    "        sorted_importance = importance[sorted_idx]\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.barplot(x=sorted_importance, y=sorted_features)\n",
    "        plt.title(f'Feature Importance: {name}')\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# === 6. SAVE BEST MODEL ===\n",
    "if best_model_object:\n",
    "    filename = f'{best_model_name.replace(\" \", \"_\")}_best_model.pkl'\n",
    "    joblib.dump(best_model_object, filename)\n",
    "    print(f\"\\nðŸ’¾ Best model saved: {best_model_name} with accuracy = {best_model_score:.4f}\")\n",
    "    print(f\"File saved as: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
